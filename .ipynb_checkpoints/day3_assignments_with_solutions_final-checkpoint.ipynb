{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Create a module similar to `sklearn's` `datasets` module\n",
    "\n",
    "Create a class called `my_sklearn`, which accepts following parameters\n",
    "\n",
    "* path: str (path to the csv file)\n",
    "* is_header: boolean (if the file has header)\n",
    "* target_variable: str (target variable)\n",
    "* feature_names: list (Not required if the file already has headers)\n",
    "* random_state: int (Optional)\n",
    "\n",
    "Define following methods.\n",
    "\n",
    "*  ** `Representation` in the format: **\n",
    "    \n",
    "    `Path: path/to/the/file.csv`\n",
    "    \n",
    "    `feature variables: ['your', 'list', 'of', 'features', 'here']`\n",
    "\n",
    "    `target variable: your_target_variable `\n",
    "     \n",
    "\n",
    "*  **`load_data()` with following parameters:**\n",
    "\n",
    "    * feature_subset: list of features to be selected (Optional)\n",
    "    * train_size: float, fraction [0, 1] of data to be selected as training set (Optional)\n",
    "    * CV_subset= \"train\", \"test\" or \"all\"\n",
    "\n",
    "**Note:** \n",
    "\n",
    "* You can use `pandas`, `numpy` and `sklearn`'s `train_test_split` libraries.\n",
    "* Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jay/miniconda3/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "class my_sklearn():\n",
    "    \n",
    "    def __init__(self, path, is_header, target_variable, feature_names=None, random_state=7):\n",
    "        \n",
    "        self. path = path\n",
    "        self.feature_names = feature_names\n",
    "        self.target_variable = target_variable\n",
    "        self.is_header = is_header\n",
    "        self.names = None\n",
    "        self.header = 0\n",
    "        \n",
    "        if not self.is_header:\n",
    "            try:\n",
    "                self.names = self.feature_names + [self.target_variable]\n",
    "            except:\n",
    "                raise AttributeError(\"Feature Names must be entered if the file does not have header.\")\n",
    "        \n",
    "        self._df = pd.read_csv(path, header=self.header, names=self.names)\n",
    "        \n",
    "        if not self.feature_names:\n",
    "            self.feature_names = list(self._df.columns)\n",
    "            self.feature_names.remove(self.target_variable)\n",
    "        \n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self.feature_subset = None\n",
    "        self.target_subset = None\n",
    "        self.CV_subset = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return \"path : {}\\nfeatures varaibles: {}\\ntarget varaibles: {}\".\\\n",
    "                format(self.path, self.feature_names, self.target_variable)\n",
    "    \n",
    "    def load_data(self, feature_subset=None, CV_subset=\"train\", train_size=None):\n",
    "        \n",
    "        self.feature_subset = feature_subset\n",
    "        self.CV_subset = CV_subset\n",
    "        self.train_size = train_size\n",
    "                \n",
    "        ##########################\n",
    "        if not self.feature_subset:\n",
    "#             print \"checked\"\n",
    "            self.feature_subset = self.feature_names\n",
    "#             print(self.feature_subset)\n",
    "        elif not isinstance(self.feature_subset, list):\n",
    "            raise TypeError(\"Please provide a list for feature subset\")\n",
    "        else:\n",
    "            for feature in self.feature_subset:\n",
    "                if feature not in self.feature_names:\n",
    "                    raise ValueError(\"{} not in features\".format(feature))\n",
    "        \n",
    "        mask = (0<self.train_size) & (self.train_size<1)\n",
    "        \n",
    "        ##########################\n",
    "        if self.CV_subset == \"all\":\n",
    "            if self.train_size:\n",
    "                raise ValueError(\"CV subset is 'all', train_size must be None\")\n",
    "            self.target = self._df[self.target_variable].as_matrix()\n",
    "            self.data = self._df[self.feature_subset].as_matrix()\n",
    "        \n",
    "        elif (self.CV_subset == \"train\") | (self.CV_subset == \"test\"):\n",
    "            \n",
    "            if not isinstance(self.train_size, int) | isinstance(self.train_size, float):\n",
    "                raise TypeError(\"Please provide train size between 0 and 1\")\n",
    "            elif not mask:\n",
    "                raise ValueError(\"Please provide train size between 0 and 1\")\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(self._df[self.feature_subset], \\\n",
    "                                                            self._df[self.target_variable], \\\n",
    "                                                            train_size=self.train_size,\n",
    "                                                            random_state=self.random_state)\n",
    "            if self.CV_subset == \"train\":\n",
    "                self.target = y_train.as_matrix()\n",
    "                self.data = X_train.as_matrix()\n",
    "            elif self.CV_subset == \"test\":\n",
    "                self.target = y_test.as_matrix()\n",
    "                self.data = X_test.as_matrix()\n",
    "        else:\n",
    "            raise ValueError(\"The value of cv_subset can only be 'train', 'test' or 'all'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = my_sklearn(\"data/titanic_train.csv\", is_header=True, target_variable=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path : data/titanic_train.csv\n",
       "features varaibles: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
       "target varaibles: Survived"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.load_data(CV_subset=\"train\", train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[206, 3, 'Strom, Miss. Telma Matilda', ..., 10.4625, 'G6', 'S'],\n",
       "       [719, 3, 'McEvoy, Mr. Michael', ..., 15.5, nan, 'Q'],\n",
       "       [836, 1, 'Compton, Miss. Sara Rebecca', ..., 83.1583, 'E49', 'C'],\n",
       "       ..., \n",
       "       [538, 1, 'LeRoy, Miss. Bertha', ..., 106.425, nan, 'C'],\n",
       "       [197, 3, 'Mernagh, Mr. Robert', ..., 7.75, nan, 'Q'],\n",
       "       [176, 3, 'Klasen, Mr. Klas Albin', ..., 7.8542, nan, 'S']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Survived'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.feature_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
